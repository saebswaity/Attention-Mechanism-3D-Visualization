# Attention Mechanism 3D Visualization

An interactive 3D visualization demonstrating how the modified attention mechanism affects word embeddings in different contexts.

## Formula

```
softmax(X·µÄX + Œ±¬∑diag(X·µÄX))¬∑X
```

Where:
- **X·µÄX** ‚Äî computes attention scores between all word vectors
- **Œ±¬∑diag(X·µÄX)** ‚Äî dampening factor that controls self-attention
- **Œ± < 0** ‚Äî increases self-attention (words stay closer to original position)
- **Œ± > 0** ‚Äî reduces self-attention (words move more toward context)

## Key Concept

The word **"apple"** starts at the same position `[2, 2, 2]` in both contexts:

### Initial Positions

**Fruit Context:**
| Word | Position |
|------|----------|
| apple | `[2, 2, 2]` |
| orange | `[3.5, 3, 1]` |
| banana | `[4, 1, 2]` |

**Tech Context:**
| Word | Position |
|------|----------|
| apple | `[2, 2, 2]` |
| iPhone | `[2, 1, 3]` |
| Mac | `[1, 3, 0.1]` |

### What happens after attention

| Context | Words | Result |
|---------|-------|--------|
| üçé Fruit | apple, orange, banana | apple moves toward fruit cluster |
| üì± Tech | apple, iPhone, Mac | apple moves toward tech cluster |

This demonstrates how **context changes meaning** ‚Äî the same word vector gets pulled toward different regions of the embedding space based on surrounding words.

## Features

- **3D vectors with arrows** from origin to each word
- **Draggable spheres** ‚Äî move any word to see how it affects attention
- **Smooth animations** ‚Äî watch vectors glide to new positions
- **Ghost spheres** ‚Äî show original positions after calculation
- **Attention lines** ‚Äî curved lines show attention weights between words
- **Live position display** ‚Äî see exact coordinates and changes (Œî)

## Controls

| Action | How |
|--------|-----|
| Rotate view | Drag empty space |
| Zoom | Scroll |
| Move word | Drag sphere |
| Change context | Click Fruit/Tech tabs |
| Adjust dampening | Use Œ± slider |
| Run attention | Click "Calculate Attention" |
| Start over | Click "Reset Positions" |

## Tech Stack

- Three.js (r128)
- OrbitControls
- DragControls
- Pure HTML/CSS/JS

## Credits

Created by collaboration between human designer and **Claude Opus 4.5** (Anthropic).

- **Design & Concept**: Human
- **Code Implementation**: Claude Opus 4.5

---

*This visualization helps understand how attention mechanisms in transformers allow the same word to have different representations based on context.*
